{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022a0b10-83a4-4207-a08c-a48ff3bcf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the assignment 1 in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f801d6-5a70-49ef-b57d-98fd9a9c2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from Helper_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04006c23-7ef4-46eb-b255-13747eea2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.layers import Input, Lambda, Embedding, LSTM, Dense, TimeDistributed, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955ea7f3-83c5-422c-9fc5-9bfc58a9c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Tokenizer class for converting the input to ouput\n",
    "\n",
    "class TokenizedDataStream:\n",
    "    def __init__(self, examples, vocab_size=10000, max_length=512):\n",
    "        self.examples = examples\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.EOS = 1\n",
    "\n",
    "        self.pt_lines, self.en_lines = self.extract_lines(examples)\n",
    "        self.pt_tokenizer, self.en_tokenizer = self.create_tokenizers(self.pt_lines, self.en_lines)\n",
    "        self.pt_sequences, self.en_sequences = self.convert_to_sequences(self.pt_lines, self.en_lines)\n",
    "\n",
    "    def extract_lines(self, examples):\n",
    "        pt_lines = [pt.numpy().decode('utf-8') for pt, _ in examples]\n",
    "        en_lines = [en.numpy().decode('utf-8') for _, en in examples]\n",
    "        return pt_lines, en_lines\n",
    "\n",
    "    def create_tokenizers(self, pt_lines, en_lines):\n",
    "        pt_tokenizer = self.create_tokenizer(pt_lines, self.vocab_size)\n",
    "        en_tokenizer = self.create_tokenizer(en_lines, self.vocab_size)\n",
    "        return pt_tokenizer, en_tokenizer\n",
    "\n",
    "    def create_tokenizer(self, lines, vocab_size):\n",
    "        tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "        tokenizer.fit_on_texts(lines)\n",
    "        return tokenizer\n",
    "\n",
    "    def convert_to_sequences(self, pt_lines, en_lines):\n",
    "        pt_sequences = self.pt_tokenizer.texts_to_sequences(pt_lines)\n",
    "        en_sequences = self.en_tokenizer.texts_to_sequences(en_lines)\n",
    "        return pt_sequences, en_sequences\n",
    "\n",
    "    def append_eos(self, inputs, targets):\n",
    "        for input, target in zip(inputs, targets):\n",
    "            # Append EOS to each sentence\n",
    "            input_seq = list(input) + [self.EOS]\n",
    "            target_seq = list(target) + [self.EOS]\n",
    "            yield np.array(input_seq), np.array(target_seq)\n",
    "\n",
    "    def get_tokenized_stream(self):\n",
    "        pt_sequences, en_sequences = self.pt_sequences, self.en_sequences\n",
    "        return self.append_eos(en_sequences, pt_sequences)\n",
    "\n",
    "    def detokenize(self, integers, type):\n",
    "        integers = list(np.squeeze(integers))\n",
    "\n",
    "        EOS = 1\n",
    "\n",
    "        if EOS in integers:\n",
    "            integers = integers[:integers.index(EOS)]\n",
    "\n",
    "        if type == \"Input\":\n",
    "            # Convert integer sequences back to text using tokenizers\n",
    "            return self.en_tokenizer.sequences_to_texts([integers])[0]\n",
    "\n",
    "        if type == \"Target\":\n",
    "            # Convert integer sequences back to text using tokenizers\n",
    "            return self.pt_tokenizer.sequences_to_texts([integers])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ec0341-2f8d-4a25-8d18-4fa08123e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3916eecc-c02b-40fd-95a1-9f5031ae1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f42c41-9f27-49a7-aa0a-e70fc91f683c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51785, 1193)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples), len(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd35653c-5869-466d-9b30-8b37c7eb6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the boundairs and batch_sizes for the bucketing\n",
    "boundaries = [8, 16, 32, 64, 128, 256, 512]\n",
    "batch_sizes = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "\n",
    "train_tokenizer = TokenizedDataStream(train_examples)\n",
    "train_stream = train_tokenizer.get_tokenized_stream()\n",
    "\n",
    "val_tokenizer = TokenizedDataStream(val_examples)\n",
    "val_stream = val_tokenizer.get_tokenized_stream()\n",
    "\n",
    "# Defining the vocab size\n",
    "target_vocab_size = train_tokenizer.en_tokenizer.num_words\n",
    "input_vocab_size = train_tokenizer.pt_tokenizer.num_words\n",
    "\n",
    "# Creating the bucket -- it is the technique to group the data of similary length in one batch and process the whole data like this\n",
    "train_batch_stream = Bucket_By_Length(\n",
    "    boundaries, batch_sizes,\n",
    "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
    ")(train_stream)\n",
    "\n",
    "eval_batch_stream = Bucket_By_Length(\n",
    "    boundaries, batch_sizes,\n",
    "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
    ")(val_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d13703c-00c0-4368-b7fa-1eb7b839dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "eval_data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "744758f6-ad2d-4a8f-9544-e0c88dc27225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "for data_point in train_batch_stream:\n",
    "    input_data,  target_data = data_point\n",
    "    input_data = tf.convert_to_tensor(input_data, dtype=tf.int32)\n",
    "    target_data = tf.convert_to_tensor(target_data, dtype=tf.int32)\n",
    "    train_data_list.append((input_data, target_data))\n",
    "\n",
    "# Load eval data\n",
    "for data_point in eval_batch_stream:\n",
    "    input_data, target_data = data_point\n",
    "    input_data = tf.convert_to_tensor(input_data, dtype=tf.int32)\n",
    "    target_data = tf.convert_to_tensor(target_data, dtype=tf.int32)\n",
    "    eval_data_list.append((input_data, target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d31d717-45c6-4d73-bb59-44a3350e9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data):\n",
    "    for input_data, target_data in data:\n",
    "        yield [input_data, target_data], target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da750390-1507-47cc-9b9a-822abf3e3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let now define the Modules of our model. We are using the functional Api of keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e79aec-05f2-4073-9631-57f7259f07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out input encoder is defined like this  --- \n",
    "# input_token -> embeddings -> token_embeddings -> LSTM*(how many encoder layers we want) -> It will return these encoder outputs\n",
    "\n",
    "def input_encoder_fn(input_vocab_size, d_model, n_encoder_layers):\n",
    "\n",
    "    \"\"\" Input encoder runs on the input sentence and creates\n",
    "    activations that will be the keys and values for attention.\n",
    "    \n",
    "    Args:\n",
    "        input_vocab_size: int: vocab size of the input\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "        n_encoder_layers: int: number of LSTM layers in the encoder\n",
    "    Returns:\n",
    "        tf.keras.Model: The input encoder\n",
    "    \"\"\"\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(None,))  # we are defining the None shape so that it can pass the variable length batch_Size\n",
    "\n",
    "    # Create an embedding layer to convert tokens to vectors\n",
    "    embedding = Embedding(input_dim=input_vocab_size, output_dim=d_model)(inputs)\n",
    "\n",
    "    # Create a list of LSTM layers\n",
    "    encoder_layers = [LSTM(units=d_model, return_sequences=True) for _ in range(n_encoder_layers)]\n",
    "\n",
    "    # Apply LSTM layers in sequence\n",
    "    activations = embedding\n",
    "    for layer in encoder_layers:\n",
    "        activations = layer(activations)\n",
    "\n",
    "    # Create the model\n",
    "    input_encoder = Model(inputs, activations)\n",
    "\n",
    "    return input_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c6e9403-7066-4e28-b83b-9654431e7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want a pre-attention-decoder \n",
    "# This will run on targets and creates a output that we will use as Queries in the attention layer.\n",
    "# Target_token -> ShiftRight(for teacher forcing) -> <SOS>+targret token -> Embeddings -> token Embeddings -> LSTM(only single layer used) -> output\n",
    "def pre_attention_decoder_fn(mode, target_vocab_size, d_model):\n",
    "    \"\"\" Pre-attention decoder runs on the targets and creates\n",
    "    activations that are used as queries in attention.\n",
    "\n",
    "    Args:\n",
    "        mode: str: 'train' or 'eval'\n",
    "        target_vocab_size: int: vocab size of the target\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "    Returns:\n",
    "        tf.keras.Model: The pre-attention decoder\n",
    "    \"\"\"\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(None,))\n",
    "\n",
    "    # Shift right to insert start-of-sentence token and implement teacher forcing during training\n",
    "    # shifted_right = ShiftRightLayer(mode=mode,n_positions=1)(inputs) # This will shift the right to insert the start of sentence token and implement teacher forcing during training\n",
    "    # model will be training or Inference -- it will behave different\n",
    "    # TO-DO -- need to add the mode function.(Here)\n",
    "    # Value to append in front\n",
    "    value_to_append = tf.constant(0, dtype=tf.int32)\n",
    "    \n",
    "    # Create a tensor with zeros of the same batch size and sequence length\n",
    "    batch_size, sequence_length, _ = target.shape\n",
    "    zero_padding = tf.zeros((batch_size,1, 1), dtype=tf.int32)\n",
    "    # print(zero_padding)\n",
    "    shifted_right = tf.concat([zero_padding, target], axis=1)\n",
    "\n",
    "    # Create an embedding layer to convert tokens to vectors\n",
    "    embedding = Embedding(input_dim=target_vocab_size, output_dim=d_model)(shifted_right)\n",
    "\n",
    "    # Create an LSTM layer\n",
    "    lstm = LSTM(units=d_model, return_sequences=True)(embedding)\n",
    "\n",
    "    # Create the model\n",
    "    pre_attention_decoder = Model(inputs, lstm)\n",
    "\n",
    "    return pre_attention_decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3ec370e-027a-4269-bb63-987b44b60208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will prepare the inputs to the attention layer. \n",
    "# We want to take in the encoder and pre-attention decoder activations and assign it to the queries, keys, and values\n",
    "# TO-DO -- Need to add the mask token here so that ( the masked token will not have effect when calculating the softmax for probabilites)\n",
    "\n",
    "def prepare_attention_input(encoder_activations, decoder_activations):\n",
    "    \"\"\"Prepare queries, keys, values, and mask for attention.\n",
    "\n",
    "    Args:\n",
    "        encoder_activations: tf.Tensor (batch_size, padded_input_length, d_model): output from the input encoder\n",
    "        decoder_activations: tf.Tensor (batch_size, padded_input_length, d_model): output from the pre-attention decoder\n",
    "        inputs: tf.Tensor (batch_size, padded_input_length): padded input tokens\n",
    "\n",
    "    Returns:\n",
    "        queries, keys, values, and mask for attention.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the keys and values to the encoder activations\n",
    "    keys = encoder_activations\n",
    "    values = encoder_activations\n",
    "\n",
    "    # Set the queries to the decoder activations\n",
    "    queries = decoder_activations\n",
    "\n",
    "    return queries, keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0a41f955-9251-4ff6-974b-910dc0974515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.input_encoder import input_encoder_fn\n",
    "from layers.pre_attention_inputs import pre_attention_decoder_fn\n",
    "def NMTAttn(input_vocab_size=1000,\n",
    "            target_vocab_size=1000,\n",
    "            d_model=1024,\n",
    "            n_encoder_layers=1,\n",
    "            n_decoder_layers=1,\n",
    "            n_attention_heads=1,\n",
    "            attention_dropout=0.0,\n",
    "            mode='train'):\n",
    "    \"\"\"Returns an LSTM sequence-to-sequence model with attention.\n",
    "\n",
    "    The input to the model is a pair (input tokens, target tokens), e.g.,\n",
    "    an English sentence (tokenized) and its translation into German (tokenized).\n",
    "\n",
    "    Args:\n",
    "        input_vocab_size: int: vocab size of the input\n",
    "        target_vocab_size: int: vocab size of the target\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "        n_encoder_layers: int: number of LSTM layers in the encoder\n",
    "        n_decoder_layers: int: number of LSTM layers in the decoder after attention\n",
    "        n_attention_heads: int: number of attention heads\n",
    "        attention_dropout: float, dropout for the attention layer\n",
    "        mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference\n",
    "\n",
    "    Returns:\n",
    "        A LSTM sequence-to-sequence model with attention.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 0: Define input layers\n",
    "    input_tokens = Input(shape=(None,))\n",
    "    target_tokens = Input(shape=(None,))\n",
    "    # masked_tokens = Input(shape=(None,))\n",
    "\n",
    "    \n",
    "    # Step 1: call the helper function to create layers for the input encoder\n",
    "    input_encoder = input_encoder_fn(input_vocab_size, d_model, n_encoder_layers)\n",
    "\n",
    "    # Step 1: call the helper function to create layers for the pre-attention decoder\n",
    "    pre_attention_decoder = pre_attention_decoder_fn(mode, target_vocab_size, d_model)\n",
    "\n",
    "    \n",
    "    # Step 2: Copy input tokens and target tokens as they will be needed later\n",
    "    concatenated_tokens = Concatenate(axis=1)([input_tokens, target_tokens]) ## Concate and stored in concated tokens.\n",
    "\n",
    "    # Step 3: Run input encoder on the input and pre-attention decoder on the target\n",
    "    input_encoder_output = input_encoder(input_tokens[:, :, tf.newaxis])  ## New-axis will just add the new dimension (B,T) now we will have (B,T,1)\n",
    "    pre_attention_decoder_output = pre_attention_decoder(target_tokens[:, :, tf.newaxis])\n",
    "\n",
    "    \n",
    "    # Step 4: Prepare queries, keys, values, and mask for attention\n",
    "    queries, keys, values = prepare_attention_input(input_encoder_output,\n",
    "                                                    pre_attention_decoder_output)\n",
    "\n",
    "    # Step 5: Run the AttentionQKV layer and nest it inside a Residual layer\n",
    "    attention_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_attention_heads, key_dim=d_model, dropout=attention_dropout)\n",
    "    \n",
    "    attention_output = attention_layer(queries, keys, values) + queries  ## Will calculate the attention and add the residual connection(queries back to model)\n",
    "\n",
    "    # TO-DO -- add the mask here \n",
    "    # Step 6: Drop attention mask (i.e., index = None)\n",
    "    # attention_output = attention_output[:, :, :, :d_model]\n",
    "    # need to add then mask will be added\n",
    "\n",
    "    # Step 7: Run the rest of the LSTM decoder ( This will be our final decoder which will take the activation_ouput and return the probabilites)\n",
    "    lstm_layers = [LSTM(units=d_model, return_sequences=True) for _ in range(n_decoder_layers)]\n",
    "    decoder_output = attention_output\n",
    "    for layer in lstm_layers:\n",
    "        decoder_output = layer(decoder_output)\n",
    "\n",
    "    # Step 8: Prepare output by making it the right size  \n",
    "    output = Dense(target_vocab_size)(decoder_output) ## Added the dense layer\n",
    "\n",
    "    # Step 9: Log-softmax for output\n",
    "    output = tf.math.log(tf.nn.softmax(output)) #Taking logSoftmax\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=[input_tokens, target_tokens], outputs=output)  # Defining the final model \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63dd893c-bbd9-421d-aaf3-11345ebca238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_13 (S  (None, None, 1)     0           ['input_26[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_12 (S  (None, None, 1)     0           ['input_25[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " model_19 (Functional)          (None, None, 1024)   18632704    ['tf.__operators__.getitem_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " model_18 (Functional)          (None, None, 1024)   18632704    ['tf.__operators__.getitem_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, None, 1024)  4198400     ['model_19[0][0]',               \n",
      " eadAttention)                                                    'model_18[0][0]',               \n",
      "                                                                  'model_18[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, None, 1024)  0           ['multi_head_attention_6[0][0]', \n",
      " mbda)                                                            'model_19[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 (None, None, 1024)   8392704     ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, None, 10000)  10250000    ['lstm_22[0][0]']                \n",
      "                                                                                                  \n",
      " tf.nn.softmax_6 (TFOpLambda)   (None, None, 10000)  0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.log_6 (TFOpLambda)     (None, None, 10000)  0           ['tf.nn.softmax_6[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 60,106,512\n",
      "Trainable params: 60,106,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(input_vocab_size, target_vocab_size)\n",
    "model = NMTAttn(input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, d_model=1024, mode='train')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "62ca8243-3fda-400e-8a0f-7f397b0e5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "# Define the optimizer with the specified learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "# Define a metric for accuracy\n",
    "accuracy_metric = SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7890a300-ebed-4423-8b8b-66dda325c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = 'output_dir/'\n",
    "\n",
    "#Remove old model if it exists to restart training\n",
    "import os\n",
    "\n",
    "if os.path.exists(output_dir + 'model.h5'):\n",
    "    os.remove(output_dir + 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ae9c1333-ce5d-4404-8bed-f8f5a50b6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "271a1035-55a8-40c4-adf7-2a0f20d4639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "((<tf.Tensor 'IteratorGetNext:0' shape=(None, None) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None) dtype=int32>), <tf.Tensor 'IteratorGetNext:2' shape=(None, None) dtype=int32>)\n",
      "(<tf.Tensor 'IteratorGetNext:0' shape=(None, None) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None) dtype=int32>) Tensor(\"IteratorGetNext:2\", shape=(None, None), dtype=int32) None\n",
      "((<tf.Tensor 'IteratorGetNext:0' shape=(None, None) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None) dtype=int32>), <tf.Tensor 'IteratorGetNext:2' shape=(None, None) dtype=int32>)\n",
      "(<tf.Tensor 'IteratorGetNext:0' shape=(None, None) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None) dtype=int32>) Tensor(\"IteratorGetNext:2\", shape=(None, None), dtype=int32) None\n",
      "20/20 [==============================] - 51s 2s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 7s 548ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 546ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 549ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 50s 2s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 528ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 550ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 550ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 528ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 520ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 521ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 528ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 530ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 54s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 546ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 54s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 54s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 578ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 53s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 520ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 50s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 5s 517ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 51s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 52s 3s/step - loss: 9.2103 - sparse_categorical_accuracy: 7.3242e-05\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 9.2103 - sparse_categorical_accuracy: 4.8828e-05\n",
      "Train Loss: 9.2103, Train Accuracy: 0.0001\n",
      "Validation Loss: 9.2103, Validation Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_data_generator = data_generator(train_data_list[:20])\n",
    "    eval_data_generator = data_generator(eval_data_list[:20])\n",
    "\n",
    "    # # Training step\n",
    "    history = model.fit(\n",
    "        train_data_generator,\n",
    "        epochs=1,  # One epoch at a time,\n",
    "        verbose=1  # Set to 1 for progress updates\n",
    "    )\n",
    "    \n",
    "    # Extract training loss and accuracy from the history object\n",
    "    train_loss = history.history['loss'][0]\n",
    "    train_accuracy = history.history['sparse_categorical_accuracy'][0]\n",
    "    \n",
    "    # Validation step\n",
    "    eval_loss, eval_accuracy = model.evaluate(eval_data_generator, verbose=1)\n",
    "    \n",
    "    # Print training and validation metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {eval_loss:.4f}, Validation Accuracy: {eval_accuracy:.4f}\")\n",
    "    \n",
    "    # Save the model checkpoint after each epoch\n",
    "    model.save(output_dir + f\"model_epoch_{epoch + 1}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6b7fc-51aa-475f-9238-0c6df40c5fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
