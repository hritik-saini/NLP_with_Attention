{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f7b77b-1108-4908-8c29-957c3494566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c78e66-d6cc-4115-a085-b0236871bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Lambda, Embedding, LSTM, Dense, TimeDistributed, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "\n",
    "\n",
    "# from Helper_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e82433-5344-4c01-aaeb-065b1e59dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def filter_by_length(max_length, min_length=0, length_keys=None, length_axis=0):\n",
    "    assert max_length is not None or min_length is not None\n",
    "    length_keys = length_keys or [0, 1]\n",
    "    length_fn = lambda x: _length_fn(x, length_axis, length_keys)\n",
    "\n",
    "    def filtered(gen):\n",
    "        for example in gen:\n",
    "            example_len = length_fn(example)\n",
    "\n",
    "            # Checking max length boundary.\n",
    "            if max_length is not None:\n",
    "                if example_len > max_length:\n",
    "                    continue\n",
    "            # Checking min length boundary.\n",
    "            if min_length is not None:\n",
    "                if example_len < min_length:\n",
    "                    continue\n",
    "            # Within bounds.\n",
    "            yield example\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def _length_fn(example, length_axis, length_keys):\n",
    "    \"\"\"Length is the maximum of shape on length_axis over length_keys.\"\"\"\n",
    "    if isinstance(example, (list, tuple)):\n",
    "        return max([example[i].shape[length_axis] for i in length_keys])\n",
    "    return example.shape[length_axis]\n",
    "\n",
    "\n",
    "def Bucket_By_Length(boundaries, batch_sizes,\n",
    "                     length_keys=None, length_axis=0, strict_pad_on_len=False):\n",
    "    \"\"\"Returns a function for bucketing inputs, see `bucket_by_length`.\"\"\"\n",
    "    length_keys = length_keys or [0, 1]\n",
    "    # In all cases so far, we use a length function of the following form.\n",
    "    length_fn = lambda x: _length_fn(x, length_axis, length_keys)\n",
    "    return lambda g: bucket_by_length(  # pylint: disable=g-long-lambda\n",
    "        g, length_fn, boundaries, batch_sizes, strict_pad_on_len)\n",
    "\n",
    "\n",
    "def bucket_by_length(generator, length_fn, boundaries, batch_sizes,\n",
    "                     strict_pad_on_len=False):\n",
    "    \"\"\"Bucket by length, like tf.data.experimental.bucket_by_sequence_length.\n",
    "\n",
    "  This function draws examples from the provided `generator` and puts an\n",
    "  example into a bucket depending on `l = length_fn(example)`. Which bucket\n",
    "  is used depends on between which `boundaries` is l. When a bucket reaches\n",
    "  its batch size, as specified by `batch_sizes`, generates a batch of\n",
    "  padded examples from this bucket.\n",
    "\n",
    "  Args:\n",
    "    generator: python generator to draw data from.\n",
    "    length_fn: a function taking the example and returning the length.\n",
    "    boundaries: a list of bucket boundaries.\n",
    "    batch_sizes: a list of batch sizes.\n",
    "    strict_pad_on_len: bool; if true we pad on the length dimension, dim[0]\n",
    "      strictly as a multiple of boundary.\n",
    "\n",
    "  Yields:\n",
    "    An input batch, which comes from one of the buckets.\n",
    "  \"\"\"\n",
    "    buckets = [[] for _ in range(len(batch_sizes))]\n",
    "    boundaries = boundaries + [math.inf]  # Max boundary is unlimited.\n",
    "    for example in generator:\n",
    "        length = length_fn(example)\n",
    "        # `bucket_idx` will always be < len(boundaries), since boundaries is right\n",
    "        # padded by `math.inf`.\n",
    "        bucket_idx = min([i for i, b in enumerate(boundaries) if length <= b])\n",
    "        buckets[bucket_idx].append(example)\n",
    "        if len(buckets[bucket_idx]) == batch_sizes[bucket_idx]:\n",
    "            batched = zip(*buckets[bucket_idx])\n",
    "            boundary = boundaries[bucket_idx]\n",
    "            boundary = None if boundary == math.inf else boundary\n",
    "            padded_batch = tuple(\n",
    "                pad_to_max_dims(x, boundary, strict_pad_on_len) for x in batched)\n",
    "            yield padded_batch\n",
    "            buckets[bucket_idx] = []\n",
    "\n",
    "\n",
    "def pad_to_max_dims(tensors, boundary=None, strict_pad_on_len=False):\n",
    "    \"\"\"Pad a tuple of tensors to a joint dimension and return their batch.\n",
    "\n",
    "  For example, a pair of tensors of shape (2, 10) and (3, 9) will be padded\n",
    "  to (3, 10) both and the returned tensor will have shape (2, 3, 10).\n",
    "\n",
    "  When boundary is specified, we try to pad all unknown dimensions to boundary\n",
    "  if possible, which can help reduce the number of different shapes occurring\n",
    "  in the tensors and speed up XLA compilation. So, for example, a pair of\n",
    "  tensors of shapes (8, 10), (8, 9) with boundary=12 will be padded to (8, 12).\n",
    "\n",
    "  One special case occurs when boundary is much higher than the padding length\n",
    "  that we'd use without boundary. For example, tensors (2, 10) and (3, 9) with\n",
    "  boundary=12 could end up padded to (12, 12), but this is very wasteful in\n",
    "  the first dimension. In that case, we will use the closest power-of-2 instead\n",
    "  of the boundary, so the we will end up padding to (4, 12) instead of (12, 12).\n",
    "\n",
    "  Args:\n",
    "    tensors: a tuple or list of tensors to pad\n",
    "    boundary: int or None; if given, expand the padded dimensions to this size\n",
    "    strict_pad_on_len: bool; if true we pad on the length dimension, dim[0]\n",
    "      strictly as a multiple of boundary.\n",
    "\n",
    "  Returns:\n",
    "    a tensor, the tensors padded together\n",
    "  \"\"\"\n",
    "    # TODO(afrozm): Unify this later.\n",
    "    if ((boundary is not None) and\n",
    "            (strict_pad_on_len or isinstance(boundary, (list, tuple)))):\n",
    "        ndim = tensors[0].ndim\n",
    "        if not isinstance(boundary, (list, tuple)):\n",
    "            boundary = [boundary] * ndim\n",
    "\n",
    "        if ndim != len(boundary):\n",
    "            raise ValueError(f'ndim != len(boundary) - '\n",
    "                             f'ndim({ndim}) vs boundary({boundary}) '\n",
    "                             f'len(boundary) = {len(boundary)}.')\n",
    "\n",
    "        max_len_per_dim = [0] * ndim\n",
    "        for tensor in tensors:\n",
    "            max_len_per_dim = [\n",
    "                max(e, s) for e, s in zip(tensor.shape, max_len_per_dim)]\n",
    "\n",
    "        # Round everything up to a multiple of boundary in the respective dimension.\n",
    "        len_per_dim = [\n",
    "            max_len_per_dim[i] if not b else b * math.ceil(max_len_per_dim[i] / b)\n",
    "            for i, b in enumerate(boundary)]\n",
    "\n",
    "        padded_tensors = [\n",
    "            np.pad(t, [(0, len_per_dim[i] - t.shape[i]) for i in range(ndim)],\n",
    "                   mode='constant', constant_values=t.dtype.type(0))\n",
    "            for t in tensors]\n",
    "\n",
    "        return np.stack(padded_tensors)\n",
    "\n",
    "    max_len_to_pad = []\n",
    "    padding_needed = False\n",
    "    dim = len(tensors[0].shape)\n",
    "    for i in range(dim):\n",
    "        max_len = max([t.shape[i] for t in tensors])\n",
    "        min_len = min([t.shape[i] for t in tensors])\n",
    "        if max_len == min_len and max_len == boundary:  # No padding needed.\n",
    "            max_len_to_pad.append(max_len)\n",
    "        elif boundary is None:\n",
    "            max_len_to_pad.append(max_len)\n",
    "            padding_needed = True\n",
    "        else:\n",
    "            padding_needed = True\n",
    "            cur_boundary = max(max_len, boundary)\n",
    "            if 2 * max_len < cur_boundary:\n",
    "                cur_boundary = 2 ** int(np.ceil(np.log2(max_len)))\n",
    "            max_len_to_pad.append(cur_boundary)\n",
    "    if not padding_needed:\n",
    "        return np.stack(tensors)\n",
    "    padded_tensors = []\n",
    "    for t in tensors:\n",
    "        pad_widths = [(0, max_len_to_pad[i] - t.shape[i]) for i in range(dim)]\n",
    "        padded_t = np.pad(t, pad_widths, mode='constant',\n",
    "                          constant_values=t.dtype.type(0))\n",
    "        padded_tensors.append(padded_t)\n",
    "    return np.stack(padded_tensors)\n",
    "\n",
    "\n",
    "def Add_Loss_Weights(id_to_mask=None):  # pylint: disable=invalid-name\n",
    "    \"\"\"Returns a function to add loss weights; see `add_loss_weights`.\"\"\"\n",
    "    return lambda g: add_loss_weights(g, id_to_mask=id_to_mask)\n",
    "\n",
    "\n",
    "def add_loss_weights(generator, id_to_mask=None):\n",
    "    \"\"\"Add weights to inputs without weights and masks by id if requested.\n",
    "\n",
    "  The generator stream is augmented in the following way:\n",
    "\n",
    "  - If the stream consists of pairs `(inputs, targets)`, a loss mask is added\n",
    "    that is creates as a tensor of ones of the same shape as targets.\n",
    "  - If `id_to_mask` is not `None`, and the stream (after the previous point)\n",
    "    has triples `(inputs, targets, weights)`, the weights are multiplied by a\n",
    "    0/1 mask that is 0 iff targets is equal to `id_to_mask` (1 otherwise).\n",
    "\n",
    "  Args:\n",
    "    generator: Stream of tuples.\n",
    "    id_to_mask: If not None, int-valued id that represents padding, as opposed\n",
    "        to true target IDs.\n",
    "\n",
    "  Yields:\n",
    "    Examples from the augmented stream.\n",
    "  \"\"\"\n",
    "    for example in generator:\n",
    "        if len(example) > 3 or len(example) < 2:\n",
    "            assert id_to_mask is None, 'Cannot automatically mask this stream.'\n",
    "            yield example\n",
    "        else:\n",
    "            if len(example) == 2:\n",
    "                weights = np.ones_like(example[1]).astype(np.float32)\n",
    "            else:\n",
    "                weights = example[2].astype(np.float32)\n",
    "            mask = 1.0 - np.equal(example[1], id_to_mask).astype(np.float32)\n",
    "            weights *= mask\n",
    "            output = (example[0], example[1], weights)\n",
    "            yield output\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ShiftRightLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_positions=1, mode='train', **kwargs):\n",
    "        super(ShiftRightLayer, self).__init__(**kwargs)\n",
    "        self.n_positions = n_positions\n",
    "        self.mode = mode\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.mode == 'predict':\n",
    "            return x\n",
    "        else:\n",
    "            # Calculate padding widths\n",
    "            pad_widths = [[0, 0], [self.n_positions, 0],\n",
    "                          [0, 0]]  # Assuming input shape [batch_size, seq_length, features]\n",
    "\n",
    "            # Pad the input tensor with zeros\n",
    "            padded = tf.pad(x, pad_widths, constant_values=0)\n",
    "\n",
    "            # Slice to remove the added padding\n",
    "            return padded[:, :-self.n_positions, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0332376b-ff53-45fc-b2c2-9e9f93982ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Tokenizer class for converting the input to ouput\n",
    "\n",
    "class TokenizedDataStream:\n",
    "    def __init__(self, examples, vocab_size=10000, max_length=512):\n",
    "        self.examples = examples\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.EOS = 1\n",
    "\n",
    "        self.pt_lines, self.en_lines = self.extract_lines(examples)\n",
    "        self.pt_tokenizer, self.en_tokenizer = self.create_tokenizers(self.pt_lines, self.en_lines)\n",
    "        self.pt_sequences, self.en_sequences = self.convert_to_sequences(self.pt_lines, self.en_lines)\n",
    "\n",
    "    def extract_lines(self, examples):\n",
    "        pt_lines = [pt.numpy().decode('utf-8') for pt, _ in examples]\n",
    "        en_lines = [en.numpy().decode('utf-8') for _, en in examples]\n",
    "        return pt_lines, en_lines\n",
    "\n",
    "    def create_tokenizers(self, pt_lines, en_lines):\n",
    "        pt_tokenizer = self.create_tokenizer(pt_lines, self.vocab_size)\n",
    "        en_tokenizer = self.create_tokenizer(en_lines, self.vocab_size)\n",
    "        return pt_tokenizer, en_tokenizer\n",
    "\n",
    "    def create_tokenizer(self, lines, vocab_size):\n",
    "        tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "        tokenizer.fit_on_texts(lines)\n",
    "        return tokenizer\n",
    "\n",
    "    def convert_to_sequences(self, pt_lines, en_lines):\n",
    "        pt_sequences = self.pt_tokenizer.texts_to_sequences(pt_lines)\n",
    "        en_sequences = self.en_tokenizer.texts_to_sequences(en_lines)\n",
    "        return pt_sequences, en_sequences\n",
    "\n",
    "    def append_eos(self, inputs, targets):\n",
    "        for input, target in zip(inputs, targets):\n",
    "            # Append EOS to each sentence\n",
    "            input_seq = list(input) + [self.EOS]\n",
    "            target_seq = list(target) + [self.EOS]\n",
    "            yield np.array(input_seq), np.array(target_seq)\n",
    "\n",
    "    def get_tokenized_stream(self):\n",
    "        pt_sequences, en_sequences = self.pt_sequences, self.en_sequences\n",
    "        return self.append_eos(en_sequences, pt_sequences)\n",
    "\n",
    "    def detokenize(self, integers, type):\n",
    "        integers = list(np.squeeze(integers))\n",
    "\n",
    "        EOS = 1\n",
    "\n",
    "        if EOS in integers:\n",
    "            integers = integers[:integers.index(EOS)]\n",
    "\n",
    "        if type == \"Input\":\n",
    "            # Convert integer sequences back to text using tokenizers\n",
    "            return self.en_tokenizer.sequences_to_texts([integers])[0]\n",
    "\n",
    "        if type == \"Target\":\n",
    "            # Convert integer sequences back to text using tokenizers\n",
    "            return self.pt_tokenizer.sequences_to_texts([integers])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e383b2a-0696-4b68-8e3a-38a4be50a327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51785, 1193)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "\n",
    "len(train_examples), len(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de131212-36ec-4799-8128-866392613c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the boundairs and batch_sizes for the bucketing\n",
    "boundaries = [8, 16, 32, 64, 128, 256, 512]\n",
    "batch_sizes = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "\n",
    "train_tokenizer = TokenizedDataStream(train_examples)\n",
    "train_stream = train_tokenizer.get_tokenized_stream()\n",
    "\n",
    "val_tokenizer = TokenizedDataStream(val_examples)\n",
    "val_stream = val_tokenizer.get_tokenized_stream()\n",
    "\n",
    "# Defining the vocab size\n",
    "target_vocab_size = train_tokenizer.en_tokenizer.num_words\n",
    "input_vocab_size = train_tokenizer.pt_tokenizer.num_words\n",
    "\n",
    "# Creating the bucket -- it is the technique to group the data of similary length in one batch and process the whole data like this\n",
    "train_batch_stream = Bucket_By_Length(\n",
    "    boundaries, batch_sizes,\n",
    "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
    ")(train_stream)\n",
    "\n",
    "eval_batch_stream = Bucket_By_Length(\n",
    "    boundaries, batch_sizes,\n",
    "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
    ")(val_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1825bc32-1558-4f0d-8722-eba73ce70f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "eval_data_list = []\n",
    "# Load train data\n",
    "for data_point in train_batch_stream:\n",
    "    input_data,  target_data = data_point\n",
    "    input_data = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
    "    target_data = tf.convert_to_tensor(target_data, dtype=tf.float32)\n",
    "    train_data_list.append((input_data, target_data))\n",
    "\n",
    "# Load eval data\n",
    "for data_point in eval_batch_stream:\n",
    "    input_data, target_data = data_point\n",
    "    input_data = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
    "    target_data = tf.convert_to_tensor(target_data, dtype=tf.float32)\n",
    "    eval_data_list.append((input_data, target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588f91a9-25e0-4adb-961e-306f44fc7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data):\n",
    "    for input_data, target_data in data:\n",
    "        yield [input_data, target_data], target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f764f3-e9a6-4771-abe6-fb8881b3b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out input encoder is defined like this  ---\n",
    "# input_token -> embeddings -> token_embeddings -> LSTM*(how many encoder layers we want) -> It will return these encoder outputs\n",
    "\n",
    "def input_encoder_fn(input_vocab_size, d_model, n_encoder_layers):\n",
    "\n",
    "    \"\"\" Input encoder runs on the input sentence and creates\n",
    "    activations that will be the keys and values for attention.\n",
    "\n",
    "    Args:\n",
    "        input_vocab_size: int: vocab size of the input\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "        n_encoder_layers: int: number of LSTM layers in the encoder\n",
    "    Returns:\n",
    "        tf.keras.Model: The input encoder\n",
    "    \"\"\"\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(None,))  # we are defining the None shape so that it can pass the variable length batch_Size\n",
    "\n",
    "    # Create an embedding layer to convert tokens to vectors\n",
    "    embedding = Embedding(input_dim=input_vocab_size, output_dim=d_model)(inputs)\n",
    "\n",
    "    # Create a list of LSTM layers\n",
    "    encoder_layers = [LSTM(units=d_model, return_sequences=True) for _ in range(n_encoder_layers)]\n",
    "\n",
    "    # Apply LSTM layers in sequence\n",
    "    activations = embedding\n",
    "    for layer in encoder_layers:\n",
    "        activations = layer(activations)\n",
    "\n",
    "    # Create the model\n",
    "    input_encoder = Model(inputs, activations)\n",
    "\n",
    "    return input_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b670794-0e1c-464e-b9af-8575e7b34d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want a pre-attention-decoder\n",
    "# This will run on targets and creates a output that we will use as Queries in the attention layer.\n",
    "# Target_token -> ShiftRight(for teacher forcing) -> <SOS>+targret token -> Embeddings -> token Embeddings -> LSTM(only single layer used) -> output\n",
    "def pre_attention_decoder_fn(mode, target_vocab_size, d_model):\n",
    "    \"\"\" Pre-attention decoder runs on the targets and creates\n",
    "    activations that are used as queries in attention.\n",
    "\n",
    "    Args:\n",
    "        mode: str: 'train' or 'eval'\n",
    "        target_vocab_size: int: vocab size of the target\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "    Returns:\n",
    "        tf.keras.Model: The pre-attention decoder\n",
    "    \"\"\"\n",
    "\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=(None,))\n",
    "\n",
    "    # Shift right to insert start-of-sentence token and implement teacher forcing during training\n",
    "    # shifted_right = ShiftRightLayer(mode=mode,n_positions=1)(inputs) # This will shift the right to insert the start of sentence token and implement teacher forcing during training\n",
    "    # model will be training or Inference -- it will behave different\n",
    "    # TO-DO -- need to add the mode function.(Here)\n",
    "    # Create a tensor with zeros of the same batch size and sequence length\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    zero_padding = tf.zeros((batch_size,1), dtype = tf.float32)\n",
    "    # print(zero_padding)\n",
    "    shifted_right = tf.concat([zero_padding, inputs[:, :-1]], axis=1)\n",
    "\n",
    "    # Create an embedding layer to convert tokens to vectors\n",
    "    embedding = Embedding(input_dim=target_vocab_size, output_dim=d_model)(shifted_right)\n",
    "\n",
    "    # Create an LSTM layer\n",
    "    lstm = LSTM(units=d_model, return_sequences=True)(embedding)\n",
    "\n",
    "    # Create the model\n",
    "    pre_attention_decoder = Model(inputs, lstm)\n",
    "\n",
    "    return pre_attention_decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25644dbd-c3c6-4f43-8c71-903b121e5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will prepare the inputs to the attention layer.\n",
    "# We want to take in the encoder and pre-attention decoder activations and assign it to the queries, keys, and values\n",
    "# TO-DO -- Need to add the mask token here so that ( the masked token will not have effect when calculating the softmax for probabilites)\n",
    "\n",
    "def prepare_attention_input(encoder_activations, decoder_activations):\n",
    "    \"\"\"Prepare queries, keys, values, and mask for attention.\n",
    "\n",
    "    Args:\n",
    "        encoder_activations: tf.Tensor (batch_size, padded_input_length, d_model): output from the input encoder\n",
    "        decoder_activations: tf.Tensor (batch_size, padded_input_length, d_model): output from the pre-attention decoder\n",
    "        inputs: tf.Tensor (batch_size, padded_input_length): padded input tokens\n",
    "\n",
    "    Returns:\n",
    "        queries, keys, values, and mask for attention.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the keys and values to the encoder activations\n",
    "    keys = encoder_activations\n",
    "    values = encoder_activations\n",
    "\n",
    "    # Set the queries to the decoder activations\n",
    "    queries = decoder_activations\n",
    "\n",
    "    return queries, keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "571a7fbf-444c-4654-a25c-34eef03ef8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMTAttn(input_vocab_size=1000,\n",
    "            target_vocab_size=1000,\n",
    "            d_model=1024,\n",
    "            n_encoder_layers=4,\n",
    "            n_decoder_layers=4,\n",
    "            n_attention_heads=8,\n",
    "            attention_dropout=0.2,\n",
    "            mode='train'):\n",
    "    \"\"\"Returns an LSTM sequence-to-sequence model with attention.\n",
    "\n",
    "    The input to the model is a pair (input tokens, target tokens), e.g.,\n",
    "    an English sentence (tokenized) and its translation into German (tokenized).\n",
    "\n",
    "    Args:\n",
    "        input_vocab_size: int: vocab size of the input\n",
    "        target_vocab_size: int: vocab size of the target\n",
    "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
    "        n_encoder_layers: int: number of LSTM layers in the encoder\n",
    "        n_decoder_layers: int: number of LSTM layers in the decoder after attention\n",
    "        n_attention_heads: int: number of attention heads\n",
    "        attention_dropout: float, dropout for the attention layer\n",
    "        mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference\n",
    "\n",
    "    Returns:\n",
    "        A LSTM sequence-to-sequence model with attention.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 0: Define input layers\n",
    "    input_tokens = Input(shape=(None,))\n",
    "    target_tokens = Input(shape=(None,))\n",
    "    # masked_tokens = Input(shape=(None,))\n",
    "\n",
    "\n",
    "    # Step 1: call the helper function to create layers for the input encoder\n",
    "    input_encoder = input_encoder_fn(input_vocab_size, d_model, n_encoder_layers)\n",
    "\n",
    "    # Step 1: call the helper function to create layers for the pre-attention decoder\n",
    "    pre_attention_decoder = pre_attention_decoder_fn(mode, target_vocab_size, d_model)\n",
    "\n",
    "\n",
    "    # Step 2: Copy input tokens and target tokens as they will be needed later\n",
    "    concatenated_tokens = Concatenate(axis=1)([input_tokens, target_tokens]) ## Concate and stored in concated tokens.\n",
    "\n",
    "    # Step 3: Run input encoder on the input and pre-attention decoder on the target\n",
    "    input_encoder_output = input_encoder(input_tokens[:, :, tf.newaxis])  ## New-axis will just add the new dimension (B,T) now we will have (B,T,1)\n",
    "    pre_attention_decoder_output = pre_attention_decoder(target_tokens[:, :, tf.newaxis])\n",
    "\n",
    "\n",
    "    # Step 4: Prepare queries, keys, values, and mask for attention\n",
    "    queries, keys, values = prepare_attention_input(input_encoder_output,\n",
    "                                                    pre_attention_decoder_output)\n",
    "\n",
    "    # Step 5: Run the AttentionQKV layer and nest it inside a Residual layer\n",
    "    attention_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_attention_heads, key_dim=d_model, dropout=attention_dropout)\n",
    "\n",
    "    attention_output = attention_layer(queries, keys, values) + queries  ## Will calculate the attention and add the residual connection(queries back to model)\n",
    "\n",
    "    # TO-DO -- add the mask here\n",
    "    # Step 6: Drop attention mask (i.e., index = None)\n",
    "    # attention_output = attention_output[:, :, :, :d_model]\n",
    "    # need to add then mask will be added\n",
    "\n",
    "    # Step 7: Run the rest of the LSTM decoder ( This will be our final decoder which will take the activation_ouput and return the probabilites)\n",
    "    lstm_layers = [LSTM(units=d_model, return_sequences=True) for _ in range(n_decoder_layers)]\n",
    "    decoder_output = attention_output\n",
    "    for layer in lstm_layers:\n",
    "        decoder_output = layer(decoder_output)\n",
    "\n",
    "    # Step 8: Prepare output by making it the right size\n",
    "    output = Dense(target_vocab_size)(decoder_output) ## Added the dense layer\n",
    "\n",
    "    # output = Dense(1)(output)\n",
    "\n",
    "    # Step 9: Log-softmax for output\n",
    "    output = tf.math.log(tf.nn.softmax(output, axis=1)) #Taking logSoftmax\n",
    "\n",
    "    # output = tf.squeeze(output, axis=-1)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=[input_tokens, target_tokens], outputs=output)  # Defining the final model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e86b63-1c4d-457b-ad59-ffd004d8a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, None, 1)     0           ['input_6[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, None, 1)     0           ['input_5[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, None, 1024)   18632704    ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, None, 1024)   43810816    ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, None, 1024)  33580032    ['model_4[0][0]',                \n",
      " eadAttention)                                                    'model_3[0][0]',                \n",
      "                                                                  'model_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, None, 1024)  0           ['multi_head_attention_1[0][0]', \n",
      " mbda)                                                            'model_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 (None, None, 1024)   8392704     ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, None, 1024)   8392704     ['lstm_10[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, None, 1024)   8392704     ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, None, 1024)   8392704     ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 10000)  10250000    ['lstm_13[0][0]']                \n",
      "                                                                                                  \n",
      " tf.nn.softmax_1 (TFOpLambda)   (None, None, 10000)  0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.log_1 (TFOpLambda)     (None, None, 10000)  0           ['tf.nn.softmax_1[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 139,844,368\n",
      "Trainable params: 139,844,368\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(input_vocab_size, target_vocab_size)\n",
    "model = NMTAttn(input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, d_model=1024, mode='train')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c7da93-2cd2-48ec-95d2-45a3e58af042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Define the optimizer with the specified learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "# Define a metric for accuracy\n",
    "accuracy_metric = SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9753025c-a153-4143-8f64-a02b0fc0402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = 'output_dir/'\n",
    "\n",
    "#Remove old model if it exists to restart training\n",
    "import os\n",
    "\n",
    "if os.path.exists(output_dir + 'model.h5'):\n",
    "    os.remove(output_dir + 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d7360f9-ffe9-410d-a8a6-a5898c0fe8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58c5915b-c107-4790-b86e-d9eb0a14de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "628/628 [==============================] - 56s 81ms/step - loss: 5.3923 - sparse_categorical_accuracy: 0.3465\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 5.3364 - sparse_categorical_accuracy: 0.3407\n",
      "Train Loss: 5.3923, Train Accuracy: 0.3465\n",
      "Validation Loss: 5.3364, Validation Accuracy: 0.3407\n",
      "Epoch 2/500\n",
      "628/628 [==============================] - 51s 81ms/step - loss: 5.1676 - sparse_categorical_accuracy: 0.3507\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 5.3512 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 3/500\n",
      "628/628 [==============================] - 51s 82ms/step - loss: 5.1387 - sparse_categorical_accuracy: 0.3512\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 5.3119 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 4/500\n",
      "628/628 [==============================] - 51s 81ms/step - loss: 5.1195 - sparse_categorical_accuracy: 0.3517\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 5.3001 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 5/500\n",
      "628/628 [==============================] - 51s 81ms/step - loss: 5.1142 - sparse_categorical_accuracy: 0.3518\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 5.3049 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 6/500\n",
      "628/628 [==============================] - 51s 81ms/step - loss: 5.1009 - sparse_categorical_accuracy: 0.3521\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 5.2903 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 7/500\n",
      "628/628 [==============================] - 51s 82ms/step - loss: 5.0937 - sparse_categorical_accuracy: 0.3521\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 5.2871 - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 8/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3500\n",
      "10/10 [==============================] - 0s 33ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 9/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 33ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 10/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 11/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Train Loss: nan, Train Accuracy: 0.3480\n",
      "Validation Loss: nan, Validation Accuracy: 0.3407\n",
      "Epoch 12/500\n",
      "628/628 [==============================] - 50s 79ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 13/500\n",
      "628/628 [==============================] - 50s 79ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 14/500\n",
      "628/628 [==============================] - 50s 79ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 15/500\n",
      "628/628 [==============================] - 50s 79ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 16/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 17/500\n",
      "628/628 [==============================] - 50s 79ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 33ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 18/500\n",
      "628/628 [==============================] - 50s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3480\n",
      "10/10 [==============================] - 0s 32ms/step - loss: nan - sparse_categorical_accuracy: 0.3407\n",
      "Epoch 19/500\n",
      "     34/Unknown - 3s 80ms/step - loss: nan - sparse_categorical_accuracy: 0.3498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m eval_data_generator \u001b[38;5;241m=\u001b[39m data_generator(eval_data_list)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# # Training step\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# One epoch at a time,\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to 1 for progress updates\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract training loss and accuracy from the history object\u001b[39;00m\n\u001b[0;32m     15\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_data_generator = data_generator(train_data_list)\n",
    "    eval_data_generator = data_generator(eval_data_list)\n",
    "\n",
    "    # # Training step\n",
    "    history = model.fit(\n",
    "        train_data_generator,\n",
    "        epochs=1,  # One epoch at a time,\n",
    "        verbose=1  # Set to 1 for progress updates\n",
    "    )\n",
    "\n",
    "    # Extract training loss and accuracy from the history object\n",
    "    train_loss = history.history['loss'][0]\n",
    "    train_accuracy = history.history['sparse_categorical_accuracy'][0]\n",
    "\n",
    "    # Validation step\n",
    "    eval_loss, eval_accuracy = model.evaluate(eval_data_generator, verbose=1)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        # Print training and validation metrics\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {eval_loss:.4f}, Validation Accuracy: {eval_accuracy:.4f}\")\n",
    "    \n",
    "        # Save the model checkpoint after each epoch\n",
    "        model.save(output_dir + f\"model_epoch_{epoch + 1}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370702f6-6362-4531-9ebb-9c84adff4cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839191c4-7b7f-4777-a0fa-93bbc1bb7beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
